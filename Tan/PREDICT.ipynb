{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertForTokenClassification, AdamW, BertModel, BertConfig\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm, trange\n",
    "from visual_test import *\n",
    "from ner_evaluate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IO_tag_values = ['PER','LOC','ORG','MISC','O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT base\n",
    "IO_model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=len(IO_tag_values)+1,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")\n",
    "IO_model.load_state_dict(torch.load('IO_BERT_MULTI.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False,use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IO_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Ch√∫c anh v√† bi·ªát ƒë·ªôi lu√¥n c√≥ th·∫≠t nhi·ªÅu s·ª©c kh·ªèe . [UNK] M√£i sau d·ªãch m·ªõi ƒë∆∞·ª£c xem nh·ªØng k·ª≥ √°n c·ªßa anh [UNK] M√† ch·ªã <text style='color:red;font-size:150%'><b> Tr√¢m </b></text> <text style='color:red;font-size:150%'><b> Anh </b></text> ƒë√¢u r·ªìi ·∫° ? M·∫•y t·∫≠p kia e ko th·∫•y . ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"\n",
    "Ch√∫c anh v√† bi·ªát ƒë·ªôi lu√¥n c√≥ th·∫≠t nhi·ªÅu s·ª©c kh·ªèe.üòö\n",
    "M√£i sau d·ªãch m·ªõi ƒë∆∞·ª£c xem nh·ªØng k·ª≥ √°n c·ªßa anh üòé\n",
    "M√† ch·ªã Tr√¢m Anh ƒë√¢u r·ªìi ·∫°? M·∫•y t·∫≠p kia e ko th·∫•y ..\n",
    "\"\"\"\n",
    "visualize(predict_text(IO_model, tokenizer, IO_tag_values ,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\" H√†nh vi c·ªßa ch·ªã ƒë√£ b·ªã t√¥i ph√°t hi·ªán \" t·∫∑c <text style='color:red;font-size:150%'><b> Vinh </b></text> <text style='color:red;font-size:150%'><b> L·ªëc </b></text> <text style='color:red;font-size:150%'><b> Xo√°y </b></text> [UNK]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "\"H√†nh vi c·ªßa ch·ªã ƒë√£ b·ªã t√¥i ph√°t hi·ªán\"t·∫∑c\n",
    "Vinh L·ªëc Xo√°yü§£\n",
    "\"\"\"\n",
    "visualize(predict_text(IO_model, tokenizer, IO_tag_values ,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style='color:red;font-size:150%'><b> Duy </b></text> <text style='color:red;font-size:150%'><b> T√¢n </b></text> <text style='color:red;font-size:150%'><b> L√™ </b></text> <text style='color:red;font-size:150%'><b> Ng·ªçc </b></text> <text style='color:red;font-size:150%'><b> L·ª£i </b></text> oke anh . Nh·ªõ cho em c√°i v·ªã tr√≠ n√†o ch·∫°y nhi·ªÅu nha [UNK] Em kh√¥ng l√†m th·ªß m√¥n ƒë√¢u : v"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Duy T√¢n L√™ Ng·ªçc L·ª£i oke anh. Nh·ªõ cho em c√°i v·ªã tr√≠ n√†o ch·∫°y nhi·ªÅu nha üôÇ Em kh√¥ng l√†m th·ªß m√¥n ƒë√¢u :v\n",
    "\"\"\"\n",
    "visualize(predict_text(IO_model, tokenizer, IO_tag_values ,text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style='color:red;font-size:150%'><b> Ken </b></text> kh√¥ng ·ªû Trong Team 4 ng∆∞·ªùi n·ªØa √† anh : <text style='color:red;font-size:150%'><b> ANH </b></text> <text style='color:red;font-size:150%'><b> VINH </b></text> , <text style='color:red;font-size:150%'><b> TR√ÇM </b></text> <text style='color:red;font-size:150%'><b> ANH </b></text> , <text style='color:red;font-size:150%'><b> TLOO </b></text> , <text style='color:red;font-size:150%'><b> KEN </b></text> <text style='color:red;font-size:150%'><b> ƒê√≥ </b></text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Ken kh√¥ng ·ªû Trong Team 4 ng∆∞·ªùi n·ªØa √† anh : ANH VINH , TR√ÇM ANH , TLOO , KEN ƒê√≥\n",
    "\"\"\"\n",
    "visualize(predict_text(IO_model, tokenizer, IO_tag_values ,text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Gi√° th·ª±c ph·∫©m t∆∞∆°i s·ªëng , s·ªØa , g·∫°o , d·∫ßu ƒÉn tƒÉng 10 - 30 % , d·ª± b√°o tƒÉng ti·∫øp tr∆∞·ªõc s·ª©c √©p c·ªßa nguy√™n li·ªáu ƒë·∫ßu v√†o , chi ph√≠ v·∫≠n chuy·ªÉn l√™n cao . Ch·ªã <text style='color:red;font-size:150%'><b> Loan </b></text> , c√¥ng nh√¢n m·ªôt c√¥ng ty may m·∫∑c ·ªü <text style='color:DarkGreen;font-size:150%'><b> qu·∫≠n </b></text> <text style='color:DarkGreen;font-size:150%'><b> B√¨nh </b></text> <text style='color:DarkGreen;font-size:150%'><b> T√¢n </b></text> ( <text style='color:DarkGreen;font-size:150%'><b> TP </b></text> <text style='color:DarkGreen;font-size:150%'><b> HCM </b></text> ) cho bi·∫øt , th√°ng 10 , gia ƒë√¨nh ch·ªã chi ti√™u tƒÉng 20 % so v·ªõi khi ch∆∞a c√≥ d·ªãch v√† tƒÉng 10 % so v·ªõi th·ªùi ƒëi·ªÉm b√πng d·ªãch . \" N·∫øu tr∆∞·ªõc d·ªãch , m·ªôt b√¨nh gas 12 kg ch·ªâ 340 . 000 ƒë·ªìng , nay tƒÉng l√™n 500 . 000 ƒë·ªìng . Ti·ªÅn xƒÉng xe tƒÉng th√™m 100 . 000 ƒë·ªìng m·ªôt th√°ng . Gi√° c√°c m·∫∑t h√†ng nh∆∞ s·ªØa , g·∫°o , th·ª±c ph·∫©m c≈©ng tƒÉng cao khi·∫øn chi ph√≠ ƒëi ch·ª£ m·ªói tu·∫ßn tƒÉng g·∫ßn 500 . 000 ƒë·ªìng . . . . \" , ch·ªã <text style='color:red;font-size:150%'><b> Loan </b></text> t√≠nh to√°n v√† cho r·∫±ng v·ªõi t√¨nh h√¨nh n√†y , gia ƒë√¨nh ch·ªã nƒÉm nay l√†m kh√¥ng c√≥ d∆∞ . Ch·ªã <text style='color:red;font-size:150%'><b> H·∫±ng </b></text> ·ªü <text style='color:DarkGreen;font-size:150%'><b> qu·∫≠n </b></text> <text style='color:DarkGreen;font-size:150%'><b> G√≤ </b></text> <text style='color:DarkGreen;font-size:150%'><b> V·∫•p </b></text> c≈©ng kh√° lo l·∫Øng khi s·ªØa b·ªôt cho em b√© ƒëang tƒÉng cao so v·ªõi tr∆∞·ªõc ƒë√¢y . H·∫ßu h·∫øt c√°c lo·∫°i s·ªØa nh·∫≠p ƒë·ªÅu tƒÉng 10 . 000 - 15 . 000 ƒë·ªìng m·ªôt h·ªôp . M·ªói th√°ng con ch·ªã u·ªëng 3 h·ªôp , chi ph√≠ tƒÉng th√™m 45 . 000 ƒë·ªìng . \" Th·ªãt c√° , rau c·ªß c≈©ng tƒÉng r·∫•t m·∫°nh 10 - 20 % so v·ªõi tr∆∞·ªõc ƒë√¢y \" , ch·ªã n√≥i ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''\n",
    "Gi√° th·ª±c ph·∫©m t∆∞∆°i s·ªëng, s·ªØa, g·∫°o, d·∫ßu ƒÉn tƒÉng 10-30%, d·ª± b√°o tƒÉng ti·∫øp tr∆∞·ªõc s·ª©c √©p c·ªßa nguy√™n li·ªáu ƒë·∫ßu v√†o, chi ph√≠ v·∫≠n chuy·ªÉn l√™n cao.\n",
    "\n",
    "Ch·ªã Loan, c√¥ng nh√¢n m·ªôt c√¥ng ty may m·∫∑c ·ªü qu·∫≠n B√¨nh T√¢n (TP HCM) cho bi·∫øt, th√°ng 10, gia ƒë√¨nh ch·ªã chi ti√™u tƒÉng 20% so v·ªõi khi ch∆∞a c√≥ d·ªãch v√† tƒÉng 10% so v·ªõi th·ªùi ƒëi·ªÉm b√πng d·ªãch.\n",
    "\n",
    "\"N·∫øu tr∆∞·ªõc d·ªãch, m·ªôt b√¨nh gas 12 kg ch·ªâ 340.000 ƒë·ªìng, nay tƒÉng l√™n 500.000 ƒë·ªìng. Ti·ªÅn xƒÉng xe tƒÉng th√™m 100.000 ƒë·ªìng m·ªôt th√°ng. Gi√° c√°c m·∫∑t h√†ng nh∆∞ s·ªØa, g·∫°o, th·ª±c ph·∫©m c≈©ng tƒÉng cao khi·∫øn chi ph√≠ ƒëi ch·ª£ m·ªói tu·∫ßn tƒÉng g·∫ßn 500.000 ƒë·ªìng....\", ch·ªã Loan t√≠nh to√°n v√† cho r·∫±ng v·ªõi t√¨nh h√¨nh n√†y, gia ƒë√¨nh ch·ªã nƒÉm nay l√†m kh√¥ng c√≥ d∆∞.\n",
    "\n",
    "Ch·ªã H·∫±ng ·ªü qu·∫≠n G√≤ V·∫•p c≈©ng kh√° lo l·∫Øng khi s·ªØa b·ªôt cho em b√© ƒëang tƒÉng cao so v·ªõi tr∆∞·ªõc ƒë√¢y. H·∫ßu h·∫øt c√°c lo·∫°i s·ªØa nh·∫≠p ƒë·ªÅu tƒÉng 10.000-15.000 ƒë·ªìng m·ªôt h·ªôp. M·ªói th√°ng con ch·ªã u·ªëng 3 h·ªôp, chi ph√≠ tƒÉng th√™m 45.000 ƒë·ªìng. \"Th·ªãt c√°, rau c·ªß c≈©ng tƒÉng r·∫•t m·∫°nh 10-20% so v·ªõi tr∆∞·ªõc ƒë√¢y\", ch·ªã n√≥i.\n",
    "    '''\n",
    "visualize(predict_text(IO_model, tokenizer, IO_tag_values ,text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "O  -   <text style='color:red;font-size:150%'><b> PERSON </b></text>  -   <text style='color:blue;font-size:150%'><b> ORGANIZATION </b></text>  -   <text style='color:DarkGreen;font-size:150%'><b> LOCATION </b></text>  -   <text style='color:Violet;font-size:150%'><b> MISC </b></text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
