{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9df6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dir_train = 'dataset/vlsp21/train.pkl'\n",
    "dir_dev = 'dataset/vlsp21/dev.pkl'\n",
    "dir_test = 'dataset/vlsp21/test.pkl'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5587a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import BertTokenizer, BertConfig, BertModel\n",
    "from TorchCRF import CRF\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "\n",
    "from utils.bert_loader import BERT_DATALOADER\n",
    "from utils.bert_evaluate import BERT_EVALUATE\n",
    "from utils.bert_predict import BERT_PREDICT\n",
    "from utils.bert_visualize import BERT_VISUALIZE\n",
    "from utils.bert_model import BERT_4_CRF, BERT_4_SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb0ff061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file mBert_Tokenizer\\config.json not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  3.612210988998413  S\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tokenizer = BertTokenizer.from_pretrained('mBert_Tokenizer', do_lower_case=False,use_fast=False)\n",
    "config = BertConfig.from_pretrained('mBert_Config', output_hidden_states=True)\n",
    "config.max_position_embeddings = 512\n",
    "\n",
    "bert_model = BertModel.from_pretrained(\n",
    "                        'mBert_Model',\n",
    "                        config=config,\n",
    "                        add_pooling_layer=False\n",
    ")\n",
    "print(\"Loading: \",time.time()-start, \" S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6253ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dir_train):\n",
    "    with open(dir_train ,'rb') as f:\n",
    "        _data = pickle.load(f)\n",
    "    return _data\n",
    "tag = ['ADDRESS','SKILL','EMAIL','PERSON','PHONENUMBER','MISCELLANEOUS','QUANTITY','PERSONTYPE',\n",
    "              'ORGANIZATION','PRODUCT','IP','LOCATION','O','DATETIME','EVENT', 'URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22c3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = read_dataset(dir_train)\n",
    "TRAIN_SET = BERT_DATALOADER(data_train, tokenizer, tag, device)\n",
    "train_dataloader = TRAIN_SET.create_dataloader()\n",
    "\n",
    "data_dev = read_dataset(dir_dev)\n",
    "DEV_SET = BERT_DATALOADER(data_dev, tokenizer, tag, device)\n",
    "dev_dataloader = DEV_SET.create_dataloader()\n",
    "\n",
    "data_test = read_dataset(dir_test)\n",
    "TEST_SET = BERT_DATALOADER(data_test, tokenizer, tag, device)\n",
    "test_dataloader = TEST_SET.create_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babea8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    '''Multi-class Focal loss implementation'''\n",
    "    def __init__(self, gamma=2, weight=None,ignore_index=-100):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.ignore_index=ignore_index\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \"\"\"\n",
    "        input: [N, C]\n",
    "        target: [N, ]\n",
    "        \"\"\"\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = (1-pt)**self.gamma * logpt\n",
    "        loss = F.nll_loss(logpt, target, self.weight,ignore_index=self.ignore_index)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, eps=0.1, reduction='mean',ignore_index=-100):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        if self.reduction=='sum':\n",
    "            loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=-1)\n",
    "            if self.reduction=='mean':\n",
    "                loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction,\n",
    "                                                           ignore_index=self.ignore_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda0c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bert 4 layer\n",
    "class BERT_LSTM_SOFTMAX(nn.Module):\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "        super(BERT_LSTM_SOFTMAX, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = bert_model\n",
    "        self.classifier_1 = nn.Linear(768, num_labels)\n",
    "        self.dropout_1 = nn.Dropout(0.2)\n",
    "        self.classifier_2 = nn.Linear(768, num_labels)\n",
    "        self.dropout_2 = nn.Dropout(0.2)\n",
    "        self.classifier_3 = nn.Linear(768, num_labels)\n",
    "        self.dropout_3 = nn.Dropout(0.2)\n",
    "        self.classifier_4 = nn.Linear(768, num_labels)\n",
    "        self.dropout_4 = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(256 + 768, num_labels)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = 4*num_labels ,hidden_size = 256 , num_layers = 4*num_labels, dropout = 0.2)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def forward_custom(self, input_ids, attention_mask=None, \n",
    "                       head_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids = input_ids, attention_mask=attention_mask)\n",
    "        out_bert = outputs[1][-1]\n",
    "        out_1 = self.dropout_1(outputs[1][-1])\n",
    "        out_2 = self.dropout_1(outputs[1][-2])\n",
    "        out_3 = self.dropout_1(outputs[1][-3])\n",
    "        out_4 = self.dropout_1(outputs[1][-4])\n",
    "        sequence_1 = self.classifier_1(out_1)\n",
    "        sequence_2 = self.classifier_1(out_2)\n",
    "        sequence_3 = self.classifier_1(out_3)\n",
    "        sequence_4 = self.classifier_1(out_4)\n",
    "        \n",
    "        sequence_output = torch.cat((sequence_1, sequence_2, sequence_3, sequence_4),-1)\n",
    "        lstm_output = self.lstm(sequence_output)\n",
    "        sequence_output = torch.cat((lstm_output[0], out_bert),-1)\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output) # bsz, seq_len, num_labels\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = FocalLoss(ignore_index=0)\n",
    "            if attention_mask is not None:\n",
    "                    active_loss = attention_mask.view(-1) == 1\n",
    "                    active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                    active_labels = labels.view(-1)[active_loss]\n",
    "                    loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                    loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "        return outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f697087a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_LSTM_SOFTMAX(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier_1): Linear(in_features=768, out_features=17, bias=True)\n",
       "  (dropout_1): Dropout(p=0.2, inplace=False)\n",
       "  (classifier_2): Linear(in_features=768, out_features=17, bias=True)\n",
       "  (dropout_2): Dropout(p=0.2, inplace=False)\n",
       "  (classifier_3): Linear(in_features=768, out_features=17, bias=True)\n",
       "  (dropout_3): Dropout(p=0.2, inplace=False)\n",
       "  (classifier_4): Linear(in_features=768, out_features=17, bias=True)\n",
       "  (dropout_4): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=17, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (lstm): LSTM(68, 256, num_layers=68, dropout=0.2)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'model/bert_lstm_softmax_ner.pt'\n",
    "model = BERT_LSTM_SOFTMAX(bert_model, num_labels=len(TRAIN_SET.tag2idx))\n",
    "model.load_state_dict(torch.load(PATH), strict=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3539f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Bar: 100%|████████████████████████████████████████████████████████████████████| 81/81 [01:55<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.14295242145013662\n",
      "Validation F1-Score: 0.6949559409847702\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      ADDRESS     0.3226    0.4444    0.3738        45\n",
      "       PERSON     0.8987    0.9580    0.9274      4428\n",
      "  PHONENUMBER     0.6190    1.0000    0.7647        26\n",
      "MISCELLANEOUS     0.4049    0.5038    0.4490       262\n",
      "     QUANTITY     0.6110    0.8175    0.6993      2263\n",
      "   PERSONTYPE     0.4655    0.8238    0.5949      1016\n",
      " ORGANIZATION     0.7960    0.8320    0.8136      5440\n",
      "      PRODUCT     0.4539    0.5383    0.4925      1553\n",
      "     LOCATION     0.7736    0.9077    0.8353      4313\n",
      "            O     0.9840    0.9486    0.9659    124694\n",
      "     DATETIME     0.5847    0.8720    0.7000      1852\n",
      "        EVENT     0.4531    0.6259    0.5257       802\n",
      "          URL     0.8056    1.0000    0.8923        87\n",
      "\n",
      "    micro avg     0.9327    0.9325    0.9326    146781\n",
      "    macro avg     0.6287    0.7902    0.6950    146781\n",
      " weighted avg     0.9439    0.9325    0.9367    146781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BERT_EVALUATE(model=model, tokenizer=tokenizer, dataloader=dev_dataloader, tag_values= ['PAD']+tag, device = device, type_dataset='dev', model_type='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf35d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Bar: 100%|██████████████████████████████████████████████████████████████████| 133/133 [03:12<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.12528892082715393\n",
      "Validation F1-Score: 0.6476554072847293\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      ADDRESS     0.1296    0.3333    0.1867        21\n",
      "        EMAIL     0.5882    1.0000    0.7407        10\n",
      "       PERSON     0.9329    0.9482    0.9405      9790\n",
      "  PHONENUMBER     0.5000    0.6250    0.5556         8\n",
      "MISCELLANEOUS     0.1442    0.2997    0.1947       297\n",
      "     QUANTITY     0.8109    0.7851    0.7978      7739\n",
      "   PERSONTYPE     0.5709    0.4401    0.4970      4183\n",
      " ORGANIZATION     0.7690    0.7670    0.7680      8808\n",
      "      PRODUCT     0.4732    0.4833    0.4782      4329\n",
      "     LOCATION     0.7396    0.8900    0.8079      4590\n",
      "            O     0.9755    0.9662    0.9708    257459\n",
      "     DATETIME     0.8229    0.9512    0.8824      4689\n",
      "        EVENT     0.2200    0.6901    0.3336       568\n",
      "          URL     0.8646    0.9677    0.9133       495\n",
      "\n",
      "    micro avg     0.9388    0.9385    0.9386    302986\n",
      "    macro avg     0.6101    0.7248    0.6477    302986\n",
      " weighted avg     0.9427    0.9385    0.9400    302986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BERT_EVALUATE(model=model, tokenizer=tokenizer, dataloader=test_dataloader, tag_values= ['PAD']+tag, device = device, type_dataset='test', model_type='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac69686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
