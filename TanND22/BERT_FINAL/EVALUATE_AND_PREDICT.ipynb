{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa579c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import BertTokenizer, BertConfig, BertModel\n",
    "from TorchCRF import CRF\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4d75be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file mBert_Tokenizer\\config.json not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  1.851839542388916  S\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tokenizer = BertTokenizer.from_pretrained('mBert_Tokenizer', do_lower_case=False,use_fast=False)\n",
    "config = BertConfig.from_pretrained('mBert_Config', output_hidden_states=True)\n",
    "config.max_position_embeddings = 512\n",
    "\n",
    "bert_model = BertModel.from_pretrained(\n",
    "                        'mBert_Model',\n",
    "                        config=config,\n",
    "                        add_pooling_layer=False\n",
    ")\n",
    "print(\"Loading: \",time.time()-start, \" S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6d250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dir_train = 'dataset/vlsp21/final_7900.pkl'\n",
    "dir_dev = 'dataset/vlsp21/dev.pkl'\n",
    "dir_test = 'dataset/vlsp21/test.pkl'\n",
    "path_model = 'model/16_bert_4_crf_ner_08750.pt'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tag = ['ADDRESS','SKILL','EMAIL','PERSON','PHONENUMBER','MISCELLANEOUS','QUANTITY','PERSONTYPE',\n",
    "              'ORGANIZATION','PRODUCT','IP','LOCATION','O','DATETIME','EVENT', 'URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e64565",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### BERT_DATALOADER #############################################\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences  \n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "class BERT_DATALOADER:\n",
    "    def __init__(self, dataset, tokenizer, tag_values,  device):\n",
    "        self.dataset = dataset\n",
    "        self.X , self.Y = split_data(self.dataset)\n",
    "        self.MAX_LEN = 256\n",
    "        self.BATCH_SIZE = 32\n",
    "        self.Epoch = 60\n",
    "        self.Patient = 15\n",
    "        self.tag_values = ['PAD'] + tag_values \n",
    "        self.tag2idx = {t: i for i, t in enumerate(self.tag_values)}\n",
    "        self.device = device\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def create_dataloader(self, mode = 'evaluation', type = 'train'):\n",
    "        X_subword, y_subword = self.add_subword2data()\n",
    "        X_padding, y_padding, attention_masks = self._padding_data(X_subword,y_subword)\n",
    "        X_tensor,y_tensor,masks = self._covert2tensor(X_padding, y_padding, attention_masks, mode)\n",
    "        if type == 'train':\n",
    "            train_data = TensorDataset(X_tensor, masks, y_tensor)\n",
    "            train_sampler = RandomSampler(train_data)\n",
    "            train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = self.BATCH_SIZE)\n",
    "            return train_dataloader\n",
    "        elif type == 'dev' or type == 'test':\n",
    "            valid_data = TensorDataset(X_tensor, masks, y_tensor)\n",
    "            valid_sampler = SequentialSampler(valid_data)\n",
    "            valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size = self.BATCH_SIZE)\n",
    "            return valid_dataloader\n",
    "    \n",
    "    def _add_subword(self, sentence, text_labels):\n",
    "        '''\n",
    "        input:\n",
    "            sentence = ['Phạm', 'Văn', 'Mạnh']\n",
    "            text_labels = ['B-PER', 'I-PER','I-PER']\n",
    "\n",
    "        output: \n",
    "            ['Phạm', 'Văn', 'M', '##ạnh'],\n",
    "            ['B-PER', 'I-PER', 'I-PER', 'I-PER']\n",
    "        '''\n",
    "        tokenized_sentence = []\n",
    "        labels = []\n",
    "        for word, label in zip(sentence, text_labels):\n",
    "            subwords = self.tokenizer.tokenize(word)\n",
    "            tokenized_sentence.extend(subwords)\n",
    "            \n",
    "            labels.extend([label] * len(subwords))\n",
    "        return tokenized_sentence, labels\n",
    "\n",
    "    def add_subword2data(self):\n",
    "        '''\n",
    "            input:\n",
    "                sentence = [['Phạm', 'Văn', 'Mạnh',..],....]\n",
    "                text_labels = [['B-PER', 'I-PER','I-PER',..],...]\n",
    "\n",
    "            output: \n",
    "                [['Phạm', 'Văn', 'M', '##ạnh',..],....],\n",
    "                [['B-PER', 'I-PER','I-PER','I-PER',..],...]\n",
    "        '''\n",
    "        tokenized_texts_and_labels = [self._add_subword(sent, labs) for sent, labs in zip(self.X, self.Y)]\n",
    "        tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "        labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n",
    "        return tokenized_texts,labels\n",
    "    \n",
    "    def _padding_data(self,X_subword,y_subword):\n",
    "        '''\n",
    "            input:\n",
    "                X = [['Phạm', 'Văn', 'M', '##ạnh',..],....]\n",
    "                Y = [['B-PER', 'I-PER','I-PER','I-PER',..],...]\n",
    "\n",
    "            output: \n",
    "            [[10,20,30,40,0,0,0,0,0,0,0,0...],...],\n",
    "            [[1, 2,3,4,5,5,5,5,5,5,5,5,5,...],...]\n",
    "        '''\n",
    "        X_padding = pad_sequences([self.tokenizer.convert_tokens_to_ids(txt) for txt in X_subword],\n",
    "                          maxlen=self.MAX_LEN, dtype=\"long\", value=0.0,\n",
    "                          truncating=\"post\", padding=\"post\")\n",
    "\n",
    "        y_padding = pad_sequences([[self.tag2idx.get(l) for l in lab] for lab in y_subword],\n",
    "                        maxlen=self.MAX_LEN, value=self.tag2idx[\"PAD\"], padding=\"post\",\n",
    "                        dtype=\"long\", truncating=\"post\")\n",
    "        attention_masks = [[float(i != 0.0) for i in ii] for ii in X_padding]\n",
    "        return X_padding, y_padding,attention_masks\n",
    "    \n",
    "    def _covert2tensor(self, X_padding, Y_padding, attention_masks, mode):\n",
    "        if mode == 'training':\n",
    "            X_tensor = torch.tensor(X_padding).to(self.device) \n",
    "            y_tensor = torch.tensor(Y_padding).to(self.device) \n",
    "            masks = torch.tensor(attention_masks).to(self.device)  \n",
    "\n",
    "        elif mode =='evaluation':\n",
    "            X_tensor = torch.tensor(X_padding).type(torch.LongTensor).to(self.device) \n",
    "            y_tensor = torch.tensor(Y_padding).type(torch.LongTensor).to(self.device) \n",
    "            masks = torch.tensor(attention_masks).type(torch.LongTensor).to(self.device) \n",
    "        return  X_tensor, y_tensor, masks\n",
    "\n",
    "\n",
    "#########################################################################################################################\n",
    "def split_data(data):\n",
    "    #(x,y)=> X= [x...] , Y= [y....]\n",
    "    X, Y = [], []\n",
    "    for sent in data:\n",
    "        temp_x = []\n",
    "        temp_y = []\n",
    "        for word in sent:\n",
    "            temp_x.append(word[0])\n",
    "            temp_y.append(word[1])\n",
    "        X.append(temp_x)\n",
    "        Y.append(temp_y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef130d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### BERT_EVALUATE#############################################\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def valuation_bert_multi(model, valid_dataloader,tag_values,device):\n",
    "    '''\n",
    "        input: \n",
    "            - model\n",
    "            - valid_dataloader\n",
    "            - tag_values: ['O', 'PER', .... ]\n",
    "            - device: cuda\n",
    "        output:\n",
    "            - report F1\n",
    "            - loss \n",
    "\n",
    "    '''\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the validation loss for this epoch.\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in tqdm(valid_dataloader, desc = 'Progress Bar'):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients,\n",
    "        # saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                            attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Move logits and labels to CPU\n",
    "        \n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    eval_loss = eval_loss / len(valid_dataloader)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "    valid_tags = [tag_values[l_i] for l in true_labels\n",
    "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "    print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags,average='micro')))\n",
    "    print(classification_report(valid_tags, pred_tags,digits = 4))\n",
    "    print(\"####################\")\n",
    "\n",
    "#################################################################################################################\n",
    "\n",
    "def valuation_bert_4_crf(model, tokenizer, valid_dataloader,tag_values,device,mode):\n",
    "    '''\n",
    "        input: \n",
    "            - model\n",
    "            - valid_dataloader\n",
    "            - tag_values: ['O', 'PER', .... ]\n",
    "            - device: cuda\n",
    "        output:\n",
    "            - report F1\n",
    "            - loss \n",
    "\n",
    "    '''\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the validation loss for this epoch.\n",
    "    predictions_f1 , true_labels_f1 = [], []\n",
    "    for batch in tqdm(valid_dataloader, desc = 'Progress Bar'):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients,\n",
    "        # saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            outputs = model.forward_custom(b_input_ids, b_input_mask, b_labels, token_type_ids=None)\n",
    "        \n",
    "        predict_labels = outputs[1]\n",
    "        label_ids = b_labels.to('cpu').numpy().tolist()\n",
    "        predictions = []\n",
    "        for predict_label in predict_labels:\n",
    "            predictions.append(predict_label)\n",
    "\n",
    "        for b_input_id, preds, labels in zip(b_input_ids, predictions, label_ids):\n",
    "            tokens = tokenizer.convert_ids_to_tokens(b_input_id.to('cpu').numpy())\n",
    "\n",
    "            new_tokens, new_labels, new_preds = [], [], []\n",
    "            for token, label_idx, pred in zip(tokens, labels, preds):\n",
    "                if token.startswith(\"##\"):\n",
    "                    new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "                else:\n",
    "                    new_labels.append(label_idx)\n",
    "                    new_preds.append(pred)\n",
    "                    new_tokens.append(token)\n",
    "            for token, pred, label in zip(new_tokens, new_preds, new_labels):\n",
    "                predictions_f1.extend([tag_values[pred]])\n",
    "                true_labels_f1.extend([tag_values[label]])\n",
    "\n",
    "    if mode == 'train':\n",
    "        print(\"Validation F1-Score: {}\".format(f1_score(true_labels_f1, predictions_f1,average='macro')))\n",
    "        print(classification_report(true_labels_f1, predictions_f1,digits = 4))\n",
    "    elif mode == 'dev':\n",
    "        labels = tag_values.copy()\n",
    "        if 'IP' in labels:\n",
    "            labels.remove('IP')\n",
    "        if 'SKILL' in labels:\n",
    "            labels.remove('SKILL')\n",
    "        if 'PAD' in labels:\n",
    "            labels.remove('PAD')\n",
    "        if 'EMAIL' in labels:\n",
    "            labels.remove('EMAIL')\n",
    "        print(\"Validation F1-Score: {}\".format(f1_score(true_labels_f1, predictions_f1,labels = labels ,average='macro')))\n",
    "        print(classification_report(true_labels_f1, predictions_f1,labels = labels ,digits = 4))\n",
    "    elif mode =='test':\n",
    "        labels = tag_values.copy()\n",
    "        if 'IP' in labels:\n",
    "            labels.remove('IP')\n",
    "        if 'SKILL' in labels:\n",
    "            labels.remove('SKILL')\n",
    "        if 'PAD' in labels:\n",
    "            labels.remove('PAD')\n",
    "        print(\"Validation F1-Score: {}\".format(f1_score(true_labels_f1, predictions_f1,labels = labels ,average='macro')))\n",
    "        print(classification_report(true_labels_f1, predictions_f1,labels = labels ,digits = 4))\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "def valuation_bert_4_sofmax(model, valid_dataloader,tag_values,device,mode):\n",
    "    '''\n",
    "        input: \n",
    "            - model\n",
    "            - valid_dataloader\n",
    "            - tag_values: ['O', 'PER', .... ]\n",
    "            - device: cuda\n",
    "        output:\n",
    "            - report F1\n",
    "            - loss \n",
    "\n",
    "    '''\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the validation loss for this epoch.\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in tqdm(valid_dataloader, desc = 'Progress Bar'):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients,\n",
    "        # saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            outputs = model.forward_custom(input_ids=b_input_ids, attention_mask=b_input_mask, \n",
    "                                       labels=b_labels,head_mask=None)\n",
    "        # Move logits and labels to CPU\n",
    "        \n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    eval_loss = eval_loss / len(valid_dataloader)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "    valid_tags = [tag_values[l_i] for l in true_labels\n",
    "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "    if mode == 'train':\n",
    "        print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags,average='macro')))\n",
    "        print(classification_report(valid_tags, pred_tags,digits = 4))\n",
    "    elif mode == 'dev':\n",
    "        labels = tag_values.copy()\n",
    "        if 'IP' in labels:\n",
    "            labels.remove('IP')\n",
    "        if 'SKILL' in labels:\n",
    "            labels.remove('SKILL')\n",
    "        if 'PAD' in labels:\n",
    "            labels.remove('PAD')\n",
    "        if 'EMAIL' in labels:\n",
    "            labels.remove('EMAIL')\n",
    "        print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags,labels = labels ,average='macro')))\n",
    "        print(classification_report(valid_tags, pred_tags,labels = labels ,digits = 4))\n",
    "    elif mode =='test':\n",
    "        labels = tag_values.copy()\n",
    "        if 'IP' in labels:\n",
    "            labels.remove('IP')\n",
    "        if 'SKILL' in labels:\n",
    "            labels.remove('SKILL')\n",
    "        if 'PAD' in labels:\n",
    "            labels.remove('PAD')\n",
    "        print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags,labels = labels ,average='macro')))\n",
    "        print(classification_report(valid_tags, pred_tags,labels = labels ,digits = 4))\n",
    "\n",
    "#################################################################################################################\n",
    "def BERT_EVALUATE(model, tokenizer, dataloader, tag_values, device, type_dataset, model_type):\n",
    "    if model_type == 'crf':\n",
    "        valuation_bert_4_crf(model ,tokenizer, dataloader, tag_values , device, type_dataset)\n",
    "    elif model_type == 'softmax':\n",
    "        valuation_bert_4_sofmax(model, dataloader, tag_values , device, type_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecef3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### BERT_PREDICT#############################################\n",
    "import torch\n",
    "from pyvi import ViTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "############################## UTILS PREDICT ########################################################\n",
    "def transform_test(test=\"\", mode='token'):\n",
    "  # ['bộ', 'văn_hóa', 'và', 'truyền_thông']\n",
    "  tokens = ViTokenizer.tokenize(test).split()\n",
    "  temp = []\n",
    "  for i, w in enumerate(tokens):\n",
    "    if mode == 'token':\n",
    "        k = w.replace(\"_\", \" \")\n",
    "        temp.append(k)\n",
    "    else:   # mode == 'word'\n",
    "        k = w.replace(\"_\", \" \").split()\n",
    "        for j in k:\n",
    "            temp.append(j)\n",
    "  return temp\n",
    "\n",
    "def tokenize_predict(tokenizer, sentence):\n",
    "  '''\n",
    "    sentence: ['văn_hóa','và','nghệ_thuật']\n",
    "    \n",
    "    output: ['văn_@@', 'h@@', 'ó@@', 'a', 'và', 'nghệ_thuật']\n",
    "  '''\n",
    "  subwords = []\n",
    "\n",
    "  for word in sentence:\n",
    "    subword = tokenizer.tokenize(word)\n",
    "\n",
    "    subwords.extend(subword)\n",
    "\n",
    "  return subwords\n",
    "#####################################################################################################\n",
    "def predict_crf(model, tokenizer, tag, device, texts):\n",
    "    test_sentence_token = transform_test(texts, 'word')\n",
    "    subwords = tokenize_predict(tokenizer, test_sentence_token)\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(subwords)],\n",
    "                              maxlen=512, dtype=\"long\", value=0.0,\n",
    "                              truncating=\"post\", padding=\"post\")\n",
    "    input_ids_tensor = torch.tensor(input_ids).type(torch.LongTensor).to(device)\n",
    "    input_mask = [[float(i != 0.0) for i in ii] for ii in input_ids]\n",
    "    input_mask_tensor = torch.tensor(input_mask).type(torch.LongTensor).to(device) \n",
    "    with torch.no_grad():\n",
    "        outputs = model.forward_custom(input_ids_tensor, input_mask_tensor)\n",
    "    predict = outputs[0]\n",
    "    \n",
    "    tags_predict = [ tag[i]  for i in  predict]\n",
    "    tags = []\n",
    "    tests = []\n",
    "    for index in range(len(subwords)):\n",
    "        if \"##\" not in subwords[index]:\n",
    "            tags.append(tags_predict[index])\n",
    "            tests.append(subwords[index])\n",
    "        else:\n",
    "            tests[-1] = tests[-1] + subwords[index].replace(\"##\",\"\")\n",
    "    return [(w,t) for w,t in zip(tests,tags)]\n",
    "\n",
    "\n",
    "def predict_softmax(model, tokenizer, tag_values, device, test_sentence):\n",
    "    #predict with model\n",
    "    model.eval()\n",
    "    test_sentence_token = transform_test(test_sentence, 'word')\n",
    "    subwords = tokenize_predict(tokenizer, test_sentence_token)\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(subwords)],\n",
    "                              maxlen=512, dtype=\"long\", value=0.0,\n",
    "                              truncating=\"post\", padding=\"post\")\n",
    "    input_ids_tensor = torch.tensor(input_ids).type(torch.LongTensor).to(device) #Fixfug here\n",
    "    input_mask = [[float(i != 0.0) for i in ii] for ii in input_ids]\n",
    "    input_mask_tensor = torch.tensor(input_mask).type(torch.LongTensor).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.forward_custom(input_ids=input_ids_tensor, attention_mask=input_mask_tensor, \n",
    "                                       labels=None,head_mask=None)\n",
    "    logits = outputs[0].detach().cpu().numpy()\n",
    "    \n",
    "    #Precroces subword\n",
    "    \n",
    "    len_subword = sum(input_ids[0] != 0)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids_tensor[0].to('cpu').numpy())[:len_subword]\n",
    "    predict = np.argmax(logits, axis=2)[0][:len_subword]\n",
    "    \n",
    "    tags_predict = [ tag_values[i]  for i in  predict]\n",
    "    \n",
    "    tags = []\n",
    "    tests = []\n",
    "    for index in range(len(tokens)):\n",
    "        if \"##\" not in tokens[index]:\n",
    "            tags.append(tags_predict[index])\n",
    "            tests.append(tokens[index])\n",
    "        else:\n",
    "            tests[-1] = tests[-1] + tokens[index].replace(\"##\",\"\")\n",
    "    \n",
    "    return [(w,t) for w,t in zip(tests,tags)]\n",
    "\n",
    "def BERT_PREDICT(model, tokenizer, tag, device, test_sentence, type_model):\n",
    "    if type_model == 'crf':\n",
    "        return predict_crf(model, tokenizer, tag, device, test_sentence)\n",
    "    elif type_model == 'softmax':\n",
    "        return predict_softmax(model, tokenizer, tag, device, test_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a468449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### BERT_VISUALIZE#############################################\n",
    "from spacy import displacy\n",
    "\n",
    "COLORS ={\n",
    "    'EMAIL':'gray', \n",
    "    'ADDRESS':'maroon',\n",
    "    'PERSON':'red',\n",
    "    'PHONENUMBER': 'purple',\n",
    "    'MISCELLANEOUS':'fuchsia',\n",
    "    'QUANTITY':'green',\n",
    "    'PERSONTYPE':'lime',\n",
    "    'ORGANIZATION':'olive',\n",
    "    'PRODUCT':'yellow',\n",
    "    'SKILL':'navy',\n",
    "    'IP':'blue',\n",
    "    'LOCATION':'teal',\n",
    "    'DATETIME':'aqua',\n",
    "    'EVENT':'darkorange',\n",
    "    'URL':'deeppink'\n",
    "}\n",
    "NER = list(COLORS.keys())\n",
    "\n",
    "OPTIONS = {'ents': NER, 'colors': COLORS}\n",
    "    \n",
    "## visualize result\n",
    "## input: predict format [(word, tag)]\n",
    "\n",
    "def BERT_VISUALIZE(arr):\n",
    "    if len(arr) < 1:\n",
    "        return None\n",
    "    text = ' '.join([i for i, j in arr])\n",
    "    pos = 0\n",
    "    start_end_labels = []\n",
    "    for word, tag in arr:\n",
    "        if len(start_end_labels) > 0 and tag == start_end_labels[-1][2]:\n",
    "            temp = [start_end_labels[-1][0], pos+len(word), tag]\n",
    "            start_end_labels[-1] = temp.copy()\n",
    "        else:\n",
    "            temp = [pos, pos+len(word), tag]\n",
    "            start_end_labels.append(temp)\n",
    "        pos += len(word) + 1\n",
    "        \n",
    "    ex = [{'text': text, 'ents': [{'start': x[0], 'end': x[1], 'label': x[2]} for x in start_end_labels if x[2]!= 0]}]\n",
    "    return displacy.render(ex, manual=True, jupyter=True, style='ent', options = OPTIONS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b935ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### BERT_MODEL#############################################\n",
    "from TorchCRF import CRF\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "log_soft = F.log_softmax\n",
    "\n",
    "class BERT_4_CRF(nn.Module):\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "        super(BERT_4_CRF, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        # 4 last of layer\n",
    "        self.classifier = nn.Linear(4*768, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first = True)\n",
    "    \n",
    "    def forward_custom(self, b_input_ids, b_input_mask,  b_labels=None, token_type_ids=None):\n",
    "        outputs = self.bert(b_input_ids, attention_mask=b_input_mask)\n",
    "        sequence_output = torch.cat((outputs[1][-1], outputs[1][-2], outputs[1][-3], outputs[1][-4]),-1)\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        \n",
    "        emission = self.classifier(sequence_output) # [32,256,17]\n",
    "        \n",
    "        if b_labels is not None:\n",
    "            loss = -self.crf(log_soft(emission, 2), b_labels, mask=b_input_mask.type(torch.uint8), reduction='mean')\n",
    "            prediction = self.crf.decode(emission, mask=b_input_mask.type(torch.uint8))\n",
    "            return [loss, prediction]\n",
    "                \n",
    "        else:\n",
    "            prediction = self.crf.decode(emission, mask=b_input_mask.type(torch.uint8))\n",
    "            return prediction\n",
    "\n",
    "\n",
    "\n",
    "class BERT_4_SOFTMAX(nn.Module):\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "        super(BERT_4_SOFTMAX, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        # 4 last of layer\n",
    "        self.classifier = nn.Linear(4*768, num_labels)\n",
    "\n",
    "    def forward_custom(self, input_ids, attention_mask=None, labels=None, head_mask=None):\n",
    "        outputs = self.bert(input_ids = input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = torch.cat((outputs[1][-1], outputs[1][-2], outputs[1][-3], outputs[1][-4]),-1)\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        \n",
    "        logits = self.classifier(sequence_output) # bsz, seq_len, num_labels\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=0)\n",
    "            if attention_mask is not None:\n",
    "                    active_loss = attention_mask.view(-1) == 1\n",
    "                    active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                    active_labels = labels.view(-1)[active_loss]\n",
    "                    loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                    loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "        return outputs  #scores, (hidden_states), (attentions)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    '''Multi-class Focal loss implementation'''\n",
    "    def __init__(self, gamma=2, weight=None,ignore_index=-100):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.ignore_index=ignore_index\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \"\"\"\n",
    "        input: [N, C]\n",
    "        target: [N, ]\n",
    "        \"\"\"\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = (1-pt)**self.gamma * logpt\n",
    "        loss = F.nll_loss(logpt, target, self.weight,ignore_index=self.ignore_index)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, eps=0.1, reduction='mean',ignore_index=-100):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        if self.reduction=='sum':\n",
    "            loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=-1)\n",
    "            if self.reduction=='mean':\n",
    "                loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction,\n",
    "                                                           ignore_index=self.ignore_index)\n",
    "\n",
    "################################################################################################################\n",
    "# Define bert 4 layer\n",
    "class BERT_LSTM_SOFTMAX(nn.Module):\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "        super(BERT_LSTM_SOFTMAX, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = bert_model\n",
    "        self.classifier_1 = nn.Linear(768, num_labels)\n",
    "        self.dropout_1 = nn.Dropout(0.2)\n",
    "        self.classifier_2 = nn.Linear(768, num_labels)\n",
    "        self.dropout_2 = nn.Dropout(0.2)\n",
    "        self.classifier_3 = nn.Linear(768, num_labels)\n",
    "        self.dropout_3 = nn.Dropout(0.2)\n",
    "        self.classifier_4 = nn.Linear(768, num_labels)\n",
    "        self.dropout_4 = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(256 + 768, num_labels)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = 4*num_labels ,hidden_size = 256 , num_layers = 4*num_labels, dropout = 0.2)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def forward_custom(self, input_ids, attention_mask=None, \n",
    "                       head_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids = input_ids, attention_mask=attention_mask)\n",
    "        out_bert = outputs[1][-1]\n",
    "        out_1 = self.dropout_1(outputs[1][-1])\n",
    "        out_2 = self.dropout_1(outputs[1][-2])\n",
    "        out_3 = self.dropout_1(outputs[1][-3])\n",
    "        out_4 = self.dropout_1(outputs[1][-4])\n",
    "        sequence_1 = self.classifier_1(out_1)\n",
    "        sequence_2 = self.classifier_1(out_2)\n",
    "        sequence_3 = self.classifier_1(out_3)\n",
    "        sequence_4 = self.classifier_1(out_4)\n",
    "        \n",
    "        sequence_output = torch.cat((sequence_1, sequence_2, sequence_3, sequence_4),-1)\n",
    "        lstm_output = self.lstm(sequence_output)\n",
    "        sequence_output = torch.cat((lstm_output[0], out_bert),-1)\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output) # bsz, seq_len, num_labels\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = FocalLoss(ignore_index=0)\n",
    "            if attention_mask is not None:\n",
    "                    active_loss = attention_mask.view(-1) == 1\n",
    "                    active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                    active_labels = labels.view(-1)[active_loss]\n",
    "                    loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                    loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "        return outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcac4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### BERT_UTILS#############################################\n",
    "import pickle\n",
    "def read_dataset(dir_train):\n",
    "    with open(dir_train ,'rb') as f:\n",
    "        _data = pickle.load(f)\n",
    "    data = [sq for sq in _data if len(sq) >= 1]\n",
    "    return data\n",
    "\n",
    "def split_data(data):\n",
    "    #(x,y)=> X= [x...] , Y= [y....]\n",
    "    X, Y = [], []\n",
    "    for sent in data:\n",
    "        temp_x = []\n",
    "        temp_y = []\n",
    "        for word in sent:\n",
    "            temp_x.append(word[0])\n",
    "            temp_y.append(word[1])\n",
    "        X.append(temp_x)\n",
    "        Y.append(temp_y)\n",
    "    return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283c05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create Dataloader\n",
    "data_train = read_dataset(dir_train)\n",
    "TRAIN_SET = BERT_DATALOADER(data_train, tokenizer, tag, device)\n",
    "train_dataloader = TRAIN_SET.create_dataloader()\n",
    "\n",
    "data_dev = read_dataset(dir_dev)\n",
    "DEV_SET = BERT_DATALOADER(data_dev, tokenizer, tag, device)\n",
    "dev_dataloader = DEV_SET.create_dataloader()\n",
    "\n",
    "data_test = read_dataset(dir_test)\n",
    "TEST_SET = BERT_DATALOADER(data_test, tokenizer, tag, device)\n",
    "test_dataloader = TEST_SET.create_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e13a9d9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_4_CRF(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (classifier): Linear(in_features=3072, out_features=17, bias=True)\n",
       "  (crf): CRF(num_tags=17)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. loading model\n",
    "model = BERT_4_CRF(bert_model, num_labels=len(TRAIN_SET.tag2idx))\n",
    "model.load_state_dict(torch.load(path_model), strict=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5574b5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Bar: 100%|████████████████████████████████████████████████████████████████████| 81/81 [01:41<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score: 0.6909863644988353\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      ADDRESS     0.3944    0.8000    0.5283        35\n",
      "       PERSON     0.9188    0.9307    0.9247      3075\n",
      "  PHONENUMBER     0.2581    1.0000    0.4103         8\n",
      "MISCELLANEOUS     0.4724    0.5128    0.4918       234\n",
      "     QUANTITY     0.6020    0.8284    0.6973      2133\n",
      "   PERSONTYPE     0.5372    0.7877    0.6388       843\n",
      " ORGANIZATION     0.7390    0.9177    0.8187      4214\n",
      "      PRODUCT     0.4349    0.5962    0.5029      1149\n",
      "     LOCATION     0.8433    0.8688    0.8559      3636\n",
      "            O     0.9856    0.9487    0.9668    110861\n",
      "     DATETIME     0.5699    0.8727    0.6896      1760\n",
      "        EVENT     0.4512    0.6609    0.5363       699\n",
      "          URL     0.8545    1.0000    0.9216        47\n",
      "\n",
      "    micro avg     0.9355    0.9354    0.9354    128694\n",
      "    macro avg     0.6201    0.8250    0.6910    128694\n",
      " weighted avg     0.9479    0.9354    0.9399    128694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3. Evaluate model\n",
    "BERT_EVALUATE(model=model, tokenizer=tokenizer, dataloader=dev_dataloader, tag_values= ['PAD']+tag, device = device, type_dataset='dev', model_type='crf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d110a630",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Bar: 100%|██████████████████████████████████████████████████████████████████| 133/133 [02:42<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score: 0.583148808905693\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      ADDRESS     0.0811    0.7500    0.1463        16\n",
      "        EMAIL     0.0000    0.0000    0.0000         7\n",
      "       PERSON     0.9438    0.9482    0.9460      6623\n",
      "  PHONENUMBER     0.1875    0.5000    0.2727         6\n",
      "MISCELLANEOUS     0.1683    0.3522    0.2277       247\n",
      "     QUANTITY     0.8044    0.8256    0.8149      7185\n",
      "   PERSONTYPE     0.6378    0.3752    0.4725      3651\n",
      " ORGANIZATION     0.7253    0.8541    0.7845      6571\n",
      "      PRODUCT     0.4527    0.5191    0.4836      2886\n",
      "     LOCATION     0.8603    0.8445    0.8523      3698\n",
      "            O     0.9784    0.9695    0.9740    232378\n",
      "     DATETIME     0.8270    0.9557    0.8867      4563\n",
      "        EVENT     0.2456    0.6481    0.3562       449\n",
      "          URL     0.9300    0.9637    0.9466       331\n",
      "\n",
      "    micro avg     0.9463    0.9463    0.9463    268611\n",
      "    macro avg     0.5602    0.6790    0.5831    268611\n",
      " weighted avg     0.9501    0.9463    0.9473    268611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BERT_EVALUATE(model=model, tokenizer=tokenizer, dataloader=test_dataloader, tag_values= ['PAD']+tag, device = device, type_dataset='test', model_type='crf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32179fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " đứng đầu danh sách thương hiệu tốt nhất của \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Interbrand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " năm \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thứ 9\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " liên tiếp \n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Năm thứ 9\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATETIME</span>\n",
       "</mark>\n",
       " liên tiếp , công ty tư vấn thương hiệu toàn cầu \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Interbrand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " đã xếp \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " vào vị trí đầu danh sách các thương hiệu giá trị nhất thế giới . Giá trị thương hiệu được \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    công ty Interbrand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " định giá cho \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " là \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    408 , 6 tỷ USD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " . Con số này tăng \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    26 %\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " so với \n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    năm ngoái\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATETIME</span>\n",
       "</mark>\n",
       " khi thương hiệu của \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " được định giá \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    323 tỷ USD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " . \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " và \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " chiếm vị trí \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thứ hai\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " và \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thứ ba\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " với mức định giá tương ứng là \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    249 tỷ USD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " và \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    210 tỷ USD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " trong khi \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " và \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Samsung\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " lọt vào top \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " . Định giá chung của \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " và \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " chiếm \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    62 , 3 %\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " tổng giá trị của \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    10\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " thương hiệu hàng đầu được đánh giá trong báo cáo \n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    năm nay\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATETIME</span>\n",
       "</mark>\n",
       " . &quot; \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " đã đa dạng hóa sản phẩm hơn trong lĩnh vực chăm sóc sức khỏe với \n",
       "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple Watch\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " hiện ghi lại nồng độ oxy trong máu , dịch vụ đăng ký trong giải trí , lưu trữ dữ liệu và âm nhạc . Thương hiệu này tiếp tục gắn bó với khách hàng và tiếp tục phát triển mạnh mẽ &quot; - Báo cáo của \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Interbrand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " viết - &quot; Cuối cùng , \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " vẫn thể hiện hướng đi đáng chú ý và giá trị thương hiệu tập trung vào việc cung cấp cho người tiêu dùng trải nghiệm đơn giản , liền mạch . Điều này đã được khẳng định khi gia tăng \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    26 %\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " về giá trị thương hiệu &quot; . \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Interbrand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " tính toán định giá thương hiệu như một thước đo sức mạnh thương hiệu , tính đến nhiều yếu tố bên trong và bên ngoài chủ quan như khả năng lãnh đạo , mức độ gắn kết và mức độ liên quan . Kết quả là đánh giá tác động của \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    một\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " công ty đối với khách hàng , nhân viên và nhà đầu tư . \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Interbrand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " cho biết , các thương hiệu mạnh tạo ra ảnh hưởng đối với người tiêu dùng , tạo ra một lượng khách hàng trung thành , thu hút và giữ chân nhân viên cũng như giảm chi phí tài chính . Theo dữ liệu lịch sử của \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Interbrand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " bắt đầu giành được chỗ đứng trước các đối thủ cạnh tranh trong phân khúc công nghệ và các tên tuổi gia dụng như \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    McDonalds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " và \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " vào \n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    năm 2012\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATETIME</span>\n",
       "</mark>\n",
       " . \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " đã vượt qua \n",
       "<mark class=\"entity\" style=\"background: olive; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Coca - Cola\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " , trở thành thương hiệu giá trị nhất thế giới vào \n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    năm 2013\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATETIME</span>\n",
       "</mark>\n",
       " .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4. Predict model\n",
    "test_sentence = '''\n",
    "Apple đứng đầu danh sách thương hiệu tốt nhất của Interbrand năm thứ 9 liên tiếp\n",
    "Năm thứ 9 liên tiếp, công ty tư vấn thương hiệu toàn cầu Interbrand đã xếp Apple vào vị trí đầu danh sách các thương hiệu giá trị nhất thế giới.\n",
    "Giá trị thương hiệu được công ty Interbrand định giá cho Apple là 408,6 tỷ USD. Con số này tăng 26% so với năm ngoái khi thương hiệu của Apple được định giá 323 tỷ USD.\n",
    "Amazon và Microsoft chiếm vị trí thứ hai và thứ ba với mức định giá tương ứng là 249 tỷ USD và 210 tỷ USD trong khi Google và Samsung lọt vào top 5. Định giá chung của Apple, Amazon và Microsoft chiếm 62,3% tổng giá trị của 10 thương hiệu hàng đầu được đánh giá trong báo cáo năm nay.\n",
    "\"Apple đã đa dạng hóa sản phẩm hơn trong lĩnh vực chăm sóc sức khỏe với Apple Watch hiện ghi lại nồng độ oxy trong máu, dịch vụ đăng ký trong giải trí, lưu trữ dữ liệu và âm nhạc. Thương hiệu này tiếp tục gắn bó với khách hàng và tiếp tục phát triển mạnh mẽ\" - Báo cáo của Interbrand viết - \"Cuối cùng, Apple vẫn thể hiện hướng đi đáng chú ý và giá trị thương hiệu tập trung vào việc cung cấp cho người tiêu dùng trải nghiệm đơn giản, liền mạch. Điều này đã được khẳng định khi gia tăng 26% về giá trị thương hiệu\".\n",
    "Interbrand tính toán định giá thương hiệu như một thước đo sức mạnh thương hiệu, tính đến nhiều yếu tố bên trong và bên ngoài chủ quan như khả năng lãnh đạo, mức độ gắn kết và mức độ liên quan. Kết quả là đánh giá tác động của một công ty đối với khách hàng, nhân viên và nhà đầu tư. Interbrand cho biết, các thương hiệu mạnh tạo ra ảnh hưởng đối với người tiêu dùng, tạo ra một lượng khách hàng trung thành, thu hút và giữ chân nhân viên cũng như giảm chi phí tài chính.\n",
    "Theo dữ liệu lịch sử của Interbrand, Apple bắt đầu giành được chỗ đứng trước các đối thủ cạnh tranh trong phân khúc công nghệ và các tên tuổi gia dụng như McDonalds và GE vào năm 2012. Apple đã vượt qua Coca-Cola, trở thành thương hiệu giá trị nhất thế giới vào năm 2013.\n",
    "'''\n",
    "prediction= BERT_PREDICT(model, tokenizer, ['PAD']+tag, device, test_sentence, 'crf')\n",
    "BERT_VISUALIZE(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
